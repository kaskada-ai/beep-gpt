{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235d821b-1ff8-4ef6-8f0b-559c95254479",
   "metadata": {},
   "source": [
    "# BeepGPT Example\n",
    "\n",
    "In this notebook, you’ll see how to train BeepGPT on your Slack history in 15 minutes using only OpenAI’s API’s and open-source Python libraries - Data Science PhD not required.\n",
    "\n",
    "We'll train BeepGPT in four steps:\n",
    "1. Pull down historical messages\n",
    "2. Build training examples\n",
    "3. Convert our examples into a training dataset of prompt/completion pairs\n",
    "4. Send our training data to OpenAI and create a fine-tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70440303",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install timestreams pandas pyarrow openai kaskada==0.6.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ea2e95-6d9d-4068-ab98-8cf94bc4d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import kaskada as kd\n",
    "import pandas\n",
    "import openai\n",
    "import getpass\n",
    "import pyarrow\n",
    "import datetime\n",
    "\n",
    "# Initialize Kaskada with a local execution context.\n",
    "kd.init_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a119b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Combine Historical Files\n",
    "\n",
    "Historical slack messages can be exported by following the instructions in Slack's [Export your workspace data](https://slack.com/help/articles/201658943-Export-your-workspace-data) web page. We'll use these messages to teach BeepGPT about the members of your workspace.\n",
    "\n",
    "The export from Slack contains a zip of numererous folders and files. After uncompressing the archive, there are folders for each public channel in your Slack workspace. Inside each folder are json files for each day, which each contain all the events from the day.\n",
    "\n",
    "We execute a short python script (utilizing pandas), to concatenate all the data files together into a single parquet file.\n",
    "\n",
    "Parquet files store data in columns instead of rows. Some benefits of Parquet include:\n",
    "* Fast queries that can fetch specific column values without reading full row data\n",
    "* Highly efficient column-wise compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a6ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_file_df(json_path):\n",
    "    df = pd.read_json(json_path, precise_float=True)\n",
    "    # drop rows where subType is not null\n",
    "    if \"subtype\" in df.columns:\n",
    "        df = df[df[\"subtype\"].isnull()]\n",
    "    # only keep these columns\n",
    "    df = df[df.columns.intersection([\"ts\", \"user\", \"text\", \"reactions\", \"thread_ts\"])]\n",
    "    return df\n",
    "\n",
    "def get_channel_df(channel_path):\n",
    "    dfs = []\n",
    "    for root, dirs, files in os.walk(channel_path):\n",
    "        for file in files:\n",
    "            dfs.append(get_file_df(os.path.join(root, file)))\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def get_export_df(export_path):\n",
    "    dfs = []\n",
    "    for root, dirs, files in os.walk(export_path):\n",
    "        for dir in dirs:\n",
    "            df = get_channel_df(os.path.join(root, dir))\n",
    "            # add channel column\n",
    "            df[\"channel\"] = dir\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f8f9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_slack_export = \"slack-export\"\n",
    "\n",
    "get_export_df(path_to_slack_export).to_parquet(\"messages.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c5682-bfe0-44ca-9a5a-52a0da74e5de",
   "metadata": {},
   "source": [
    "## Read Historical Messages\n",
    "\n",
    "Load messages with Kaskada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d224bec-e5a1-4c67-8764-e3dcdbc5e0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_time</th>\n",
       "      <th>_key</th>\n",
       "      <th>ts</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>channel</th>\n",
       "      <th>reactions</th>\n",
       "      <th>thread_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-26 08:29:35.262898944</td>\n",
       "      <td>general</td>\n",
       "      <td>1.690360e+09</td>\n",
       "      <td>U05JQJJDJ6P</td>\n",
       "      <td>old message 1</td>\n",
       "      <td>general</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-26 08:29:36.582019072</td>\n",
       "      <td>general</td>\n",
       "      <td>1.690360e+09</td>\n",
       "      <td>U05JQJJDJ6P</td>\n",
       "      <td>old message 2</td>\n",
       "      <td>general</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-26 08:30:09.651159040</td>\n",
       "      <td>demo</td>\n",
       "      <td>1.690360e+09</td>\n",
       "      <td>U05JQJJDJ6P</td>\n",
       "      <td>old message in demo channel</td>\n",
       "      <td>demo</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-26 08:30:13.550578944</td>\n",
       "      <td>random</td>\n",
       "      <td>1.690360e+09</td>\n",
       "      <td>U05JQJJDJ6P</td>\n",
       "      <td>old message in random channel</td>\n",
       "      <td>random</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-26 08:30:40.229079040</td>\n",
       "      <td>random</td>\n",
       "      <td>1.690360e+09</td>\n",
       "      <td>U05JQJJDJ6P</td>\n",
       "      <td>old thread in random channel</td>\n",
       "      <td>random</td>\n",
       "      <td>None</td>\n",
       "      <td>1.690360e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _time     _key            ts         user  \\\n",
       "0 2023-07-26 08:29:35.262898944  general  1.690360e+09  U05JQJJDJ6P   \n",
       "1 2023-07-26 08:29:36.582019072  general  1.690360e+09  U05JQJJDJ6P   \n",
       "2 2023-07-26 08:30:09.651159040     demo  1.690360e+09  U05JQJJDJ6P   \n",
       "3 2023-07-26 08:30:13.550578944   random  1.690360e+09  U05JQJJDJ6P   \n",
       "4 2023-07-26 08:30:40.229079040   random  1.690360e+09  U05JQJJDJ6P   \n",
       "\n",
       "                            text  channel reactions     thread_ts  \n",
       "0                  old message 1  general      None           NaN  \n",
       "1                  old message 2  general      None           NaN  \n",
       "2    old message in demo channel     demo      None           NaN  \n",
       "3  old message in random channel   random      None           NaN  \n",
       "4   old thread in random channel   random      None  1.690360e+09  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load events from a Parquet file\n",
    "# Use the \"ts\" column as the time associated with each row, \n",
    "# and the \"channel\" column as the entity associated with each row.\n",
    "messages = kd.sources.Parquet(\n",
    "    path = \"./messages.parquet\", \n",
    "    time_column = \"ts\", \n",
    "    key_column = \"channel\",\n",
    "    time_unit = \"s\",\n",
    ")\n",
    "\n",
    "# View the first 5 events\n",
    "messages.preview(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5076d2bf-6830-460b-a9cb-948d8f106edc",
   "metadata": {},
   "source": [
    "## Build examples\n",
    "\n",
    "Fine-tuning examples will teach the model the specific users who are interested in a given conversation. \n",
    "\n",
    "Each example consists of a \"prompt\" containing the state of a conversation at a point in time and a \"completion\" containing the users (if any) who were interested in the conversation. \n",
    "\n",
    "BeepGPT uses several ways to measure interest, for example, replying to a message, or adding an emoji reaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7d2a45-eb89-47ce-b471-a39ad8c7bbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_time</th>\n",
       "      <th>_key</th>\n",
       "      <th>conversation</th>\n",
       "      <th>engaged_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-26 08:29:36.262898944</td>\n",
       "      <td>{'channel': 'general', 'thread': None}</td>\n",
       "      <td>[{'ts': 1690360175.262899, 'user': 'U05JQJJDJ6...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-26 08:29:36.582019072</td>\n",
       "      <td>{'channel': 'general', 'thread': None}</td>\n",
       "      <td>[{'ts': 1690360175.262899, 'user': 'U05JQJJDJ6...</td>\n",
       "      <td>[U05JQJJDJ6P]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-26 08:29:37.582019072</td>\n",
       "      <td>{'channel': 'general', 'thread': None}</td>\n",
       "      <td>[{'ts': 1690360175.262899, 'user': 'U05JQJJDJ6...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-26 08:30:10.651159040</td>\n",
       "      <td>{'channel': 'demo', 'thread': None}</td>\n",
       "      <td>[{'ts': 1690360209.651159, 'user': 'U05JQJJDJ6...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-26 08:30:14.550578944</td>\n",
       "      <td>{'channel': 'random', 'thread': None}</td>\n",
       "      <td>[{'ts': 1690360213.550579, 'user': 'U05JQJJDJ6...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _time                                    _key  \\\n",
       "0 2023-07-26 08:29:36.262898944  {'channel': 'general', 'thread': None}   \n",
       "1 2023-07-26 08:29:36.582019072  {'channel': 'general', 'thread': None}   \n",
       "2 2023-07-26 08:29:37.582019072  {'channel': 'general', 'thread': None}   \n",
       "3 2023-07-26 08:30:10.651159040     {'channel': 'demo', 'thread': None}   \n",
       "4 2023-07-26 08:30:14.550578944   {'channel': 'random', 'thread': None}   \n",
       "\n",
       "                                        conversation  engaged_users  \n",
       "0  [{'ts': 1690360175.262899, 'user': 'U05JQJJDJ6...             []  \n",
       "1  [{'ts': 1690360175.262899, 'user': 'U05JQJJDJ6...  [U05JQJJDJ6P]  \n",
       "2  [{'ts': 1690360175.262899, 'user': 'U05JQJJDJ6...             []  \n",
       "3  [{'ts': 1690360209.651159, 'user': 'U05JQJJDJ6...             []  \n",
       "4  [{'ts': 1690360213.550579, 'user': 'U05JQJJDJ6...             []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Messages come from Slack in chronological order, mixing concurrent conversations together.\n",
    "# Let's re-group messages by thread and/or channel.\n",
    "messages = messages.with_key(kd.record({\n",
    "    \"channel\": messages.col(\"channel\"),\n",
    "    \"thread\": messages.col(\"thread_ts\"),\n",
    "}))\n",
    "\n",
    "# To understand a converstion we need more than the most recent message.\n",
    "# We build a rolling window of messages over the most recent messages.\n",
    "conversations = (\n",
    "    messages\n",
    "    .select(\"user\", \"ts\", \"text\", \"reactions\")\n",
    "    .collect(max=20)\n",
    ")\n",
    "\n",
    "# We want to know who's interested in a conversation, but we only learn that later.\n",
    "# Shift the conversation forward in time so we can associate it with reactions that happen during that time.\n",
    "shifted_conversations = conversations.shift_by(datetime.timedelta(seconds=1))\n",
    "\n",
    "# One signal that someone is interested in a conversation is that they react to it.\n",
    "# Collect all the users who reacted to the conversation in the past 5m\n",
    "# (the period of time the prompt was shifted across)\n",
    "reaction_users = (\n",
    "    messages\n",
    "    .collect(window=kd.windows.Trailing(datetime.timedelta(seconds=1)), max=100)\n",
    "    .col(\"reactions\").flatten()\n",
    "    .col(\"users\").flatten()\n",
    ")\n",
    "\n",
    "# Another signal is that someone responds to the conversation.\n",
    "# Collect all the users to posted messages in the past 5m.\n",
    "participating_users = (\n",
    "    messages\n",
    "    .collect(window=kd.windows.Trailing(datetime.timedelta(seconds=1)), max=100)\n",
    "    .col(\"user\")\n",
    ")\n",
    "\n",
    "# Now we can bring together conversations with the reactions that occurred after the conversation occurred.\n",
    "# We're combining timelines defind at different times here, so we filter the result to the times of the shifted conversations.\n",
    "# This functions similar to a \"left join\".\n",
    "history = (\n",
    "    kd.record({\n",
    "        \"conversation\": shifted_conversations, \n",
    "        \"engaged_users\": reaction_users.union(participating_users),\n",
    "    })\n",
    "    .filter(shifted_conversations.is_not_null())\n",
    ")\n",
    "\n",
    "history.preview(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fa9bd-9c40-403d-a7ee-a15620a88418",
   "metadata": {},
   "source": [
    "## Create training dataset\n",
    "\n",
    "To prepare our fine-tuning data for OpenAI, we'll use Scikit-Learn for preprocessing. This step ensures that each user is represented by a single \"token\", and that the conversation is formatted in a way that is easy for the model to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db46ca8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_time</th>\n",
       "      <th>_key</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-26 08:29:36.262898944</td>\n",
       "      <td>{'channel': 'general', 'thread': None}</td>\n",
       "      <td>old message 1 \\n\\n###\\n\\n</td>\n",
       "      <td>0 end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-26 08:29:36.582019072</td>\n",
       "      <td>{'channel': 'general', 'thread': None}</td>\n",
       "      <td>old message 1 \\n\\n###\\n\\n</td>\n",
       "      <td>2 end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-26 08:29:37.582019072</td>\n",
       "      <td>{'channel': 'general', 'thread': None}</td>\n",
       "      <td>old message 2 \\n\\n old message 1 \\n\\n###\\n\\n</td>\n",
       "      <td>0 end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-26 08:30:10.651159040</td>\n",
       "      <td>{'channel': 'demo', 'thread': None}</td>\n",
       "      <td>old message in demo channel \\n\\n###\\n\\n</td>\n",
       "      <td>0 end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-26 08:30:14.550578944</td>\n",
       "      <td>{'channel': 'random', 'thread': None}</td>\n",
       "      <td>old message in random channel \\n\\n###\\n\\n</td>\n",
       "      <td>0 end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _time                                    _key  \\\n",
       "0 2023-07-26 08:29:36.262898944  {'channel': 'general', 'thread': None}   \n",
       "1 2023-07-26 08:29:36.582019072  {'channel': 'general', 'thread': None}   \n",
       "2 2023-07-26 08:29:37.582019072  {'channel': 'general', 'thread': None}   \n",
       "3 2023-07-26 08:30:10.651159040     {'channel': 'demo', 'thread': None}   \n",
       "4 2023-07-26 08:30:14.550578944   {'channel': 'random', 'thread': None}   \n",
       "\n",
       "                                         prompt completion  \n",
       "0                     old message 1 \\n\\n###\\n\\n      0 end  \n",
       "1                     old message 1 \\n\\n###\\n\\n      2 end  \n",
       "2  old message 2 \\n\\n old message 1 \\n\\n###\\n\\n      0 end  \n",
       "3       old message in demo channel \\n\\n###\\n\\n      0 end  \n",
       "4     old message in random channel \\n\\n###\\n\\n      0 end  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# We're going to generate per-token probability estimates, so each user needs to correspond to a single token.\n",
    "# This list will map each user-id string to an integer.\n",
    "labels = [\"nil\"]\n",
    "\n",
    "# Given a conversation, format it for an LLM prompt.\n",
    "# Put each message on a new line, and add a prompt/completion separator at the end of the string.\n",
    "@kd.udf(\"f<N: any>(x: N) -> string\")\n",
    "def format_prompt(batch: pd.Series):\n",
    "    # Concatenate messages and add a separator\n",
    "    return batch.map(lambda c: \"\\n\\n\".join([msg[\"text\"].strip() for msg in reversed(c)])  + \" \\n\\n###\\n\\n\")\n",
    "\n",
    "# Given a list of engaged users, format it for an LLM completion.\n",
    "# Randomly pick a single user (if there are multiple), or return \"nil\" if nobody engaged\n",
    "# NOTE: Predicting a single user rather than a list of them improves model performance\n",
    "@kd.udf(\"g<N: any>(x: N) -> string\")\n",
    "def format_completion(batch: pd.Series):\n",
    "    # Extend labels\n",
    "    global labels\n",
    "    for new_label in np.unique(batch.explode().dropna()):\n",
    "        if new_label not in labels:\n",
    "            labels.append(new_label)\n",
    "\n",
    "    return batch.map(lambda u: \" \" + str(labels.index(random.choice(u) if len(u) > 0 else \"nil\")) + \" end\")\n",
    "\n",
    "# Convert our structured data into unstructured training examples.\n",
    "# This requires string manipulations that Kaskada doesn't provide, but we can easily drop down to Python using a UDF.\n",
    "examples = kd.record({\n",
    "    \"prompt\": history.col(\"conversation\").pipe(format_prompt),\n",
    "    \"completion\": history.col(\"engaged_users\").pipe(format_completion),\n",
    "})\n",
    "\n",
    "examples.preview(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c86fe98-8a80-45a9-9b28-f357e9d6ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote examples to 'examples.jsonl'\n",
      "wrote labels to 'labels.json'\n"
     ]
    }
   ],
   "source": [
    "# Write examples to file\n",
    "examples.to_pandas()[[\"prompt\", \"completion\"]].to_json(\"examples.jsonl\", orient='records', lines=True)\n",
    "print(\"Wrote examples to 'examples.jsonl'\")\n",
    "\n",
    "# Write our user-id<->label mapping to file\n",
    "with open('labels.json', 'w') as f:\n",
    "    json.dump(labels, f)\n",
    "print(\"wrote labels to 'labels.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc60311-5ca1-49f3-8e35-4070174e0258",
   "metadata": {},
   "source": [
    "## Fine-tune a custom model\n",
    "\n",
    "Finally, we'll send our fine-tuning examples to OpenAI to create a custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83914ada-d108-422b-b4c0-7a0d9576d031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import cli\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Initialize OpenAI\n",
    "openai.api_key = getpass.getpass('OpenAI: API Key')\n",
    "\n",
    "# Verifiy data format, split for training & validation, upload to OpenAI\n",
    "args = SimpleNamespace(file='./examples.jsonl', quiet=True)\n",
    "cli.FineTune.prepare_data(args)\n",
    "training_id = cli.FineTune._get_or_upload('./examples_prepared_train.jsonl', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002771e-2569-4fae-8215-01d5f96502f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model using OpenAI's fine-tuning API\n",
    "resp = openai.FineTune.create(\n",
    "    training_file = training_id,\n",
    "    model = \"curie\",\n",
    "    n_epochs = 8,\n",
    "    learning_rate_multiplier = 0.02,\n",
    "    suffix = \"coversation_users\"\n",
    ")\n",
    "\n",
    "# Fine-tuning can take awhile, so keep track of this ID\n",
    "print(f'Fine-tuning model with job ID: \"{resp[\"id\"]}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
