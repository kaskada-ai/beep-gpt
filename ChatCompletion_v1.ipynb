{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatCompletion v1\n",
    "\n",
    "### Goal\n",
    "\n",
    "Let users specify notification topics, for example:\n",
    "\n",
    "\"Hey BeepGPT, let me know when thereâ€™s an important engineering decision being made about the Fraud Detection Project.\"\n",
    "\n",
    "### Method\n",
    "\n",
    "Use chat completion with a single-shot example to determine if a user should be notified.\n",
    "\n",
    "#### Pros:\n",
    "* Easy implementation: Doesn't require a vector database or fine-tuning\n",
    "* Fast response\n",
    "\n",
    "#### Cons:\n",
    "* Limited to small notification sets. If there were 1000s of users each with different notification requests, this method would probably not work.\n",
    "* Expensive to run\n",
    "\n",
    "### Notes:\n",
    "\n",
    "This notebook was primarily created as a baseline. Future notebooks will explore completing the same task with different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the tools, initiate the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q kaskada==0.6.0a4 openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, getpass\n",
    "\n",
    "# Initialize OpenAI\n",
    "openai.api_key = getpass.getpass('OpenAI: API Key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import kaskada as kd\n",
    "\n",
    "# Initialize Kaskada with a local execution context.\n",
    "kd.init_session()\n",
    "\n",
    "# set pandas to display all floats with 6 decimal places\n",
    "pd.options.display.float_format = '{:.6f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull in the user list, create a `format_user()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_json(\"slack-generation.users.json\")\n",
    "\n",
    "columns_to_keep = [\"id\", \"team_id\", \"name\", \"deleted\", \"real_name\", \"is_bot\", \"updated\"]\n",
    "\n",
    "users_df.drop(columns=users_df.columns.difference(columns_to_keep), inplace=True)\n",
    "\n",
    "users = {}\n",
    "for user in users_df.to_dict(orient='index').values():\n",
    "    users[user[\"id\"]] = user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(user_id):\n",
    "    return users[user_id] if user_id in users.keys() else None\n",
    "\n",
    "def format_user(user_id):\n",
    "    user = get_user(user_id)\n",
    "    return f\"{user['name']} ({user_id})\" if user else f\"({user_id})\"\n",
    "\n",
    "format_user(\"UBB9D2B01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the slack data, clean the message text, format message users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load events from a Parquet file\n",
    "#\n",
    "# if you wan to load in your own slack data, change this to the path of your output file from 1.1 above\n",
    "# otherwise continue with `slack-generation.parquet`, which contains generated slack data for\n",
    "# example purposes. See the `slack-generation/notebook.ipynb` notebook for more info.\n",
    "input_file = \"slack-generation.parquet\"\n",
    "\n",
    "# Use the \"ts\" column as the time associated with each row,\n",
    "# and the \"channel\" column as the entity associated with each row.\n",
    "raw_msgs = await kd.sources.Parquet.create(\n",
    "    input_file,\n",
    "    time_column = \"ts\",\n",
    "    key_column = \"channel\",\n",
    "    time_unit = \"s\"\n",
    ")\n",
    "raw_msgs.preview(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "@kd.udf(\"f<N: any>(x: N) -> string\")\n",
    "def format_users(batch: pd.Series):\n",
    "    # Apply to each row in the batch\n",
    "    return batch.map(format_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text\n",
    "import re\n",
    "\n",
    "def strip_code_blocks(line):\n",
    "    return re.sub(r\"```.*?```\", '', line)\n",
    "\n",
    "def user_repl(match_obj):\n",
    "    user_id = match_obj.group(1)\n",
    "    return format_user(user_id)\n",
    "\n",
    "def update_users(line):\n",
    "    return re.sub(r\"<@(.*?)>\", user_repl, line)\n",
    "\n",
    "def clean_message(text):\n",
    "        text = strip_code_blocks(update_users(text)).strip()\n",
    "        return None if text == \"\" else text\n",
    "\n",
    "@kd.udf(\"f<N: any>(x: N) -> string\")\n",
    "def clean_text(batch: pd.Series):\n",
    "    # Apply to each row in the batch\n",
    "    return batch.map(clean_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_msgs = raw_msgs.extend({\n",
    "    \"text\": raw_msgs.col(\"text\").pipe(clean_text),\n",
    "    \"user\": raw_msgs.col(\"user\").pipe(format_users)\n",
    "})\n",
    "formatted_msgs.preview(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the non-threaded messages into threaded messages. See `FineTuning_v2.ipynb` for more details on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "ts = formatted_msgs.col(\"ts\")\n",
    "thread_ts = formatted_msgs.col(\"thread_ts\")\n",
    "\n",
    "# split messages into two subgroups: threads and non-threads\n",
    "threads = formatted_msgs.filter(thread_ts.is_not_null())\n",
    "non_threads = formatted_msgs.filter(thread_ts.is_null())\n",
    "\n",
    "# for non-threads, consider a message a new conversation when\n",
    "# more than 10 mins have elapsed since the previous message\n",
    "is_new = ts.seconds_since_previous() > timedelta(minutes=10)\n",
    "\n",
    "# Eventually this will just be: `thread_ts = ts.first(window=kd.windows.Since(is_new, start=\"inclusive\"))`\n",
    "#\n",
    "# However, `Since()` is currently exclusive on the start of the window, inclusive on the end.\n",
    "# But we need inclusive on the start and exclusive on the end.\n",
    "#\n",
    "# The hack below does what we need until `Since()` provides additional options for inclusivity\n",
    "shifted_non_threads = non_threads.shift_by(timedelta(microseconds=0.001))\n",
    "shifted_ts = shifted_non_threads.lag(1).col(\"ts\").first(window=kd.windows.Since(is_new))\n",
    "thread_ts = ts.if_(is_new).else_(shifted_ts)\n",
    "\n",
    "# create threads_ts column for non-threaded messages\n",
    "non_threads_threads = non_threads.extend({\"thread_ts\": thread_ts}).filter(ts.is_not_null().and_(thread_ts.is_not_null()))\n",
    "\n",
    "# re-join the two message subgroups\n",
    "joined = threads.else_(non_threads_threads)\n",
    "\n",
    "# join non-threads and threads back up, and key by conversations\n",
    "messages = joined.with_key(kd.record({\n",
    "        \"channel\": joined.col(\"channel\"),\n",
    "        \"thread\": joined.col(\"thread_ts\"),\n",
    "    }))\n",
    "messages.preview(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect up all the messages, reactions, users in each conversation. output just the final collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kd.udf(\"f<N: any>(x: N) -> string\")\n",
    "def format_message(batch: pd.Series):\n",
    "    def formatter(raw):\n",
    "        return f\"{raw['user']} --> {raw['text']}\" # --> {raw['reactions']}\"\n",
    "    return batch.map(formatter)\n",
    "\n",
    "@kd.udf(\"f<N: any>(x: N) -> string\")\n",
    "def format_messages(batch: pd.Series):\n",
    "    def formatter(raw):\n",
    "        return \"\\n---\\n\".join(raw)\n",
    "    return batch.map(formatter)\n",
    "\n",
    "@kd.udf(\"f<N: any>(x: N) -> string\")\n",
    "def extract_users(batch: pd.Series):\n",
    "    def get_users(raw):\n",
    "        users = [raw[\"user\"]]\n",
    "        # for user in json.loads(raw[\"reactions\"]).keys():\n",
    "        #     if user not in users:\n",
    "        #         users.append(user)\n",
    "        return json.dumps(users)\n",
    "    return batch.map(get_users)\n",
    "\n",
    "@kd.udf(\"f<N: any>(x: N) -> string\")\n",
    "def unique_users(batch: pd.Series):\n",
    "    def get_users(raw):\n",
    "        users = []\n",
    "        for user_set in raw:\n",
    "            users.extend(json.loads(user_set))\n",
    "        return json.dumps(list(set(users)))\n",
    "    return batch.map(get_users)\n",
    "\n",
    "conversations = kd.record({\n",
    "    # \"conversation\": messages.select(\"user\", \"text\", \"reactions\").pipe(format_message).collect(max=None).pipe(format_messages),\n",
    "    # \"users\": messages.select(\"user\", \"reactions\").pipe(extract_users).collect(max=None).pipe(unique_users),\n",
    "    \"conversation\": messages.select(\"user\", \"text\").pipe(format_message).collect(max=None).pipe(format_messages),\n",
    "    \"users\": messages.select(\"user\").pipe(extract_users).collect(max=None).pipe(unique_users),\n",
    "})\n",
    "\n",
    "conversations_df = conversations.to_pandas(results=kd.results.Snapshot())\n",
    "conversations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use ChatCompletion to see if any of these conversations fall into the following groupings:\n",
    "\n",
    "* Tell me about engineering discussions related to the Supply Chain Management project\n",
    "* Alert me when people are making streaming technology decisions\n",
    "* Poke me when there are people chatting about SRE topics like monitoring and alerting\n",
    "* Let me know when people are talking about their weekends\n",
    "* Inform me of any important discussions happening on the Fraud Detection project\n",
    "\n",
    "First set up the prompt and the single-shot example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "You are a helpful assistant. You respond `true` or `false` if a passed conversation\n",
    "matches a specific request. You should respond with just the request-id and `true`\n",
    "or `false`, in json format. A conversation may match no requests, one request, or\n",
    "many requests.\n",
    "\n",
    "Conversations will be passed in plain text, where the person writing and their\n",
    "text is separated by an arrow like this: -->. And `---` characters on their own\n",
    "indicate that the next line will contain the text from the next user in the\n",
    "conversation.\n",
    "\n",
    "The requests are:\n",
    "* ID1 - Tell me about engineering discussions related to the Supply Chain Management project\n",
    "* ID2 - Alert me when people are making streaming technology decisions\n",
    "* ID3 - Poke me when there are people chatting about SRE topics like monitoring and alerting\n",
    "* ID4 - Let me know when people are talking about their weekends\n",
    "* ID5 - Inform me of any important discussions happening on the Fraud Detection project\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "userf (UEA27BBFF) --> Great engagement so far, team! To delve deeper into the topic of\n",
    "Software-defined networking (SDN) integration, let's share implementation experiences,\n",
    "and discuss the potential impact of SDN on our Network Monitoring project.\n",
    "---\n",
    "usera (U3E44CFA1) --> UserF, Let's delve into the technical intricacies of SDN\n",
    "integration, such as the architecture of SDN controllers, protocols like OpenFlow,\n",
    "and the challenges of achieving seamless integration between SDNand our streaming\n",
    "technologies.\n",
    "---\n",
    "usere (U03CC4325) --> UserA, initiating thread 76 focused on Software-defined\n",
    "networking (SDN) integration is an excellent proposal. Let's discuss the various\n",
    "aspects of SDN integration, including the real-world benefits of leveraging SDN\n",
    "in network monitoring.\n",
    "\"\"\"\n",
    "\n",
    "assistant = '{\"ID1\": false, \"ID2\": false, \"ID3\": true, \"ID4\": false, \"ID5\": false}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate ChatCompletions and output the results. Run the code in a way that we can resume if an error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only re-run this cell to restart the process\n",
    "rows_processed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-run this cell as often as needed until the process is completed\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "with open(\"ChatCompletion_v1_results.jsonl\", \"a\") as out:\n",
    "  for row in conversations_df.iterrows():\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if row[0] < rows_processed:\n",
    "      continue\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "      # model choices: gpt-4, gpt-4-32k, gpt-3.5-turbo, gpt-3.5-turbo-16k\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user},\n",
    "        {\"role\": \"assistant\", \"content\": assistant},\n",
    "        {\"role\": \"user\", \"content\": row[1][\"conversation\"]}\n",
    "      ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "\n",
    "    result = { \"id\": row[1][\"_key\"], \"result\": json.loads(response)}\n",
    "    out.write(json.dumps(result) + \"\\n\")\n",
    "    out.flush()\n",
    "\n",
    "    rows_processed += 1\n",
    "    print(rows_processed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
